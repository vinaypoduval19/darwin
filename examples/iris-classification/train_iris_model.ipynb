{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Iris Species Classification\n",
        "\n",
        "This notebook trains a Random Forest classifier to predict iris species.\n",
        "\n",
        "**Dataset**: Iris Dataset (Fisher, 1936)\n",
        "- 150 samples of iris flowers\n",
        "- Target: Species (Setosa, Versicolor, Virginica)\n",
        "\n",
        "**Features**:\n",
        "- `sepal_length`: Sepal length (cm)\n",
        "- `sepal_width`: Sepal width (cm)\n",
        "- `petal_length`: Petal length (cm)\n",
        "- `petal_width`: Petal width (cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas numpy scikit-learn mlflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# MLflow imports\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow import set_tracking_uri, set_experiment\n",
        "from mlflow.client import MlflowClient\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_mlflow(mlflow_uri: str, username: str, password: str) -> MlflowClient:\n",
        "    \"\"\"Configure MLflow tracking and return client.\"\"\"\n",
        "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = username\n",
        "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = password\n",
        "    \n",
        "    set_tracking_uri(mlflow_uri)\n",
        "    client = MlflowClient(mlflow_uri)\n",
        "    \n",
        "    print(f\"‚úÖ MLflow tracking URI: {mlflow_uri}\")\n",
        "    return client\n",
        "\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"Load Iris dataset and prepare train/test splits.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä LOADING DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    iris = load_iris(as_frame=True)\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    \n",
        "    # Rename columns to match feature names without spaces\n",
        "    X.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "    \n",
        "    # Target names\n",
        "    target_names = iris.target_names.tolist()\n",
        "    \n",
        "    print(f\"Dataset: Iris\")\n",
        "    print(f\"Samples: {X.shape[0]:,}\")\n",
        "    print(f\"Features: {X.shape[1]}\")\n",
        "    print(f\"\\nFeature names:\")\n",
        "    for i, col in enumerate(X.columns, 1):\n",
        "        print(f\"  {i}. {col}\")\n",
        "    \n",
        "    print(f\"\\nTarget classes:\")\n",
        "    for i, name in enumerate(target_names):\n",
        "        count = (y == i).sum()\n",
        "        print(f\"  {i}. {name}: {count} samples\")\n",
        "    \n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTrain samples: {X_train.shape[0]:,}\")\n",
        "    print(f\"Test samples: {X_test.shape[0]:,}\")\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, X.columns.tolist(), target_names\n",
        "\n",
        "\n",
        "def train_model(X_train, y_train, X_test, y_test, hyperparams: dict):\n",
        "    \"\"\"Train Random Forest classifier and return predictions.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üöÄ TRAINING MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(\"Hyperparameters:\")\n",
        "    for key, value in hyperparams.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    model = RandomForestClassifier(**hyperparams)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    print(\"‚úÖ Training completed!\")\n",
        "    \n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    return model, y_train_pred, y_test_pred\n",
        "\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, dataset_name=\"Test\"):\n",
        "    \"\"\"Calculate and return evaluation metrics.\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    \n",
        "    return {\n",
        "        f\"{dataset_name.lower()}_accuracy\": accuracy,\n",
        "        f\"{dataset_name.lower()}_precision\": precision,\n",
        "        f\"{dataset_name.lower()}_recall\": recall,\n",
        "        f\"{dataset_name.lower()}_f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "def log_to_mlflow(model, X_train, y_train, X_test, y_test, \n",
        "                  y_train_pred, y_test_pred, hyperparams, feature_names, target_names):\n",
        "    \"\"\"Log model, parameters, and metrics to MLflow.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìù LOGGING TO MLFLOW\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Log hyperparameters\n",
        "    for key, value in hyperparams.items():\n",
        "        mlflow.log_param(key, value)\n",
        "    \n",
        "    # Calculate and log metrics\n",
        "    train_metrics = calculate_metrics(y_train, y_train_pred, \"Train\")\n",
        "    test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
        "    all_metrics = {**train_metrics, **test_metrics}\n",
        "    \n",
        "    for metric_name, metric_value in all_metrics.items():\n",
        "        mlflow.log_metric(metric_name, metric_value)\n",
        "    \n",
        "    print(\"\\nüìà Model Performance:\")\n",
        "    print(f\"  Training Accuracy: {train_metrics['train_accuracy']:.4f}\")\n",
        "    print(f\"  Training F1: {train_metrics['train_f1']:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_metrics['test_accuracy']:.4f}\")\n",
        "    print(f\"  Test Precision: {test_metrics['test_precision']:.4f}\")\n",
        "    print(f\"  Test Recall: {test_metrics['test_recall']:.4f}\")\n",
        "    print(f\"  Test F1: {test_metrics['test_f1']:.4f}\")\n",
        "    \n",
        "    # Print confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    print(f\"\\n  Confusion Matrix:\")\n",
        "    print(f\"  {cm}\")\n",
        "    \n",
        "    # Create model signature\n",
        "    signature = infer_signature(X_train, model.predict(X_train))\n",
        "    input_example = X_test.head(1)\n",
        "    \n",
        "    # Save and log model\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        local_model_path = os.path.join(tmpdir, \"model\")\n",
        "        \n",
        "        mlflow.sklearn.save_model(\n",
        "            model,\n",
        "            local_model_path,\n",
        "            signature=signature,\n",
        "            input_example=input_example\n",
        "        )\n",
        "        \n",
        "        mlflow.log_artifacts(local_model_path, artifact_path=\"model\")\n",
        "        print(\"‚úÖ Model artifacts logged successfully!\")\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "\n",
        "def create_sample_payload(X_test, y_test, model, feature_names, target_names):\n",
        "    \"\"\"Create realistic sample prediction payload.\"\"\"\n",
        "    # Get one sample from each class if possible\n",
        "    samples = []\n",
        "    \n",
        "    for class_idx in range(len(target_names)):\n",
        "        class_samples = X_test[y_test == class_idx]\n",
        "        if len(class_samples) > 0:\n",
        "            sample = class_samples.iloc[0]\n",
        "            actual_class = class_idx\n",
        "            predicted_class = model.predict(sample.values.reshape(1, -1))[0]\n",
        "            \n",
        "            samples.append({\n",
        "                \"features\": sample.to_dict(),\n",
        "                \"actual_class\": int(actual_class),\n",
        "                \"actual_species\": target_names[actual_class],\n",
        "                \"predicted_class\": int(predicted_class),\n",
        "                \"predicted_species\": target_names[predicted_class]\n",
        "            })\n",
        "    \n",
        "    # Return first sample for main payload\n",
        "    return samples[0] if samples else None\n",
        "\n",
        "\n",
        "def register_model(client: MlflowClient, model_name: str, run_id: str, experiment_id: str):\n",
        "    \"\"\"Register model in MLflow Model Registry.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üì¶ REGISTERING MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    model_uri = f\"runs:/{run_id}/model\"\n",
        "    \n",
        "    # Create registered model if it doesn't exist\n",
        "    try:\n",
        "        client.get_registered_model(model_name)\n",
        "        print(f\"‚ÑπÔ∏è  Model '{model_name}' already exists in registry\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            client.create_registered_model(model_name)\n",
        "            print(f\"‚úÖ Created registered model: {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Could not create registered model: {e}\")\n",
        "    \n",
        "    # Create model version\n",
        "    try:\n",
        "        result = client.create_model_version(\n",
        "            name=model_name,\n",
        "            source=model_uri,\n",
        "            run_id=run_id\n",
        "        )\n",
        "        print(f\"‚úÖ Model version registered successfully!\")\n",
        "        print(f\"   Model Name: {model_name}\")\n",
        "        print(f\"   Version: {result.version}\")\n",
        "        print(f\"   Run ID: {run_id}\")\n",
        "        return result.version\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Model registration failed (model still usable via run URI): {e}\")\n",
        "        print(f\"   You can deploy using: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def print_deployment_info(run_id: str, experiment_id: str, sample_payload: dict):\n",
        "    \"\"\"Print deployment instructions and sample payloads.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéâ TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(f\"\\nüìã Run Information:\")\n",
        "    print(f\"  Run ID: {run_id}\")\n",
        "    print(f\"  Experiment ID: {experiment_id}\")\n",
        "    print(f\"  Model URI: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üöÄ DEPLOYMENT PAYLOAD (deploy-model API)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    deploy_payload = {\n",
        "        \"serve_name\": \"iris-classifier\",\n",
        "        \"model_uri\": f\"mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\",\n",
        "        \"env\": \"local\",\n",
        "        \"cores\": 2,\n",
        "        \"memory\": 4,\n",
        "        \"node_capacity\": \"spot\",\n",
        "        \"min_replicas\": 1,\n",
        "        \"max_replicas\": 3\n",
        "    }\n",
        "    \n",
        "    print(json.dumps(deploy_payload, indent=2))\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä SAMPLE PREDICTION PAYLOAD\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    predict_payload = {\n",
        "        \"features\": sample_payload[\"features\"]\n",
        "    }\n",
        "    \n",
        "    print(json.dumps(predict_payload, indent=2))\n",
        "    \n",
        "    print(f\"\\nüí° Expected Output:\")\n",
        "    print(f\"  Actual Species: {sample_payload['actual_species']} (class {sample_payload['actual_class']})\")\n",
        "    print(f\"  Model Prediction: {sample_payload['predicted_species']} (class {sample_payload['predicted_class']})\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìù FEATURE DESCRIPTIONS\")\n",
        "    print(\"=\" * 80)\n",
        "    features = sample_payload[\"features\"]\n",
        "    print(f\"\"\"\n",
        "  Sepal Length: {features['sepal_length']:.2f} cm\n",
        "  Sepal Width:  {features['sepal_width']:.2f} cm\n",
        "  Petal Length: {features['petal_length']:.2f} cm\n",
        "  Petal Width:  {features['petal_width']:.2f} cm\n",
        "    \"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Train Iris Classification Model\")\n",
        "    parser.add_argument(\n",
        "        \"--mlflow-uri\",\n",
        "        default=\"http://darwin-mlflow-lib.darwin.svc.cluster.local:8080\",\n",
        "        help=\"MLflow tracking URI\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--username\",\n",
        "        default=\"dhruv.mehta@dream11.com\",\n",
        "        help=\"MLflow username\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--password\",\n",
        "        default=\"dhruv.mehta@dream11.com\",\n",
        "        help=\"MLflow password\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--experiment-name\",\n",
        "        default=\"iris_classification\",\n",
        "        help=\"MLflow experiment name\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model-name\",\n",
        "        default=\"IrisClassifierRF\",\n",
        "        help=\"Registered model name\"\n",
        "    )\n",
        "    \n",
        "    args, _ = parser.parse_known_args()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üå∏ IRIS SPECIES CLASSIFICATION MODEL TRAINING\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    \n",
        "    # Setup MLflow\n",
        "    client = setup_mlflow(args.mlflow_uri, args.username, args.password)\n",
        "    set_experiment(experiment_name=args.experiment_name)\n",
        "    print(f\"‚úÖ Experiment: {args.experiment_name}\")\n",
        "    \n",
        "    # Load data\n",
        "    X_train, X_test, y_train, y_test, feature_names, target_names = load_and_prepare_data()\n",
        "    \n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"n_estimators\": 100,\n",
        "        \"max_depth\": 10,\n",
        "        \"min_samples_split\": 2,\n",
        "        \"min_samples_leaf\": 1,\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1\n",
        "    }\n",
        "    \n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(run_name=f\"rf_iris_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
        "        # Train model\n",
        "        model, y_train_pred, y_test_pred = train_model(\n",
        "            X_train, y_train, X_test, y_test, hyperparams\n",
        "        )\n",
        "        \n",
        "        # Log to MLflow\n",
        "        metrics = log_to_mlflow(\n",
        "            model, X_train, y_train, X_test, y_test,\n",
        "            y_train_pred, y_test_pred, hyperparams, feature_names, target_names\n",
        "        )\n",
        "        \n",
        "        # Get run information\n",
        "        run_id = mlflow.active_run().info.run_id\n",
        "        experiment_id = mlflow.active_run().info.experiment_id\n",
        "        \n",
        "        # Create sample payload\n",
        "        sample_payload = create_sample_payload(X_test, y_test, model, feature_names, target_names)\n",
        "    \n",
        "    # Register model (outside of run context)\n",
        "    version = register_model(client, args.model_name, run_id, experiment_id)\n",
        "    \n",
        "    # Print deployment information\n",
        "    print_deployment_info(run_id, experiment_id, sample_payload)\n",
        "    \n",
        "    print(\"\\n‚úÖ Script completed successfully!\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
